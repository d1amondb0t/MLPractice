{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13 - Loading and Preprocessing Data with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "if IS_COLAB or IS_KAGGLE:\n",
    "    %pip install -q -U tfx\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"data\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "if IS_COLAB or IS_KAGGLE:\n",
    "    %pip install -q -U tfx\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"data\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "  print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x:x*2)\n",
    "for item in dataset:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ghafr\\AppData\\Local\\Temp\\ipykernel_14872\\2240472679.py:1: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.unbatch()`.\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.apply(tf.data.experimental.unbatch())\n",
    "for item in dataset:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x<10)\n",
    "for item in dataset:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(3):\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000014?line=0'>1</a>\u001b[0m X_mean, X_std \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000014?line=1'>2</a>\u001b[0m n_inputs \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000014?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(line):\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "X_mean, X_std = []\n",
    "n_inputs = 8\n",
    "\n",
    "def preprocess(line):\n",
    "  defs = [0.] * n_inputs * [tf.constant([], dtype=tf.float32)]\n",
    "  fields = tf.io.decoe_csv(line,record_defautls=defs)\n",
    "  x = tf.stack(fields[:-1])\n",
    "  y = tf.stack(fields[-1:])\n",
    "  return (x - X_mean) / X_std, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffter_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "  dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "  dataset = dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length = n_readers, num_parallel_calls = n_read_threads)\n",
    "  dataset = dataset.shuffle(shuffle_buffter_size)\n",
    "  dataset = dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  return dataset.prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_reader_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000016?line=0'>1</a>\u001b[0m train_filepaths, valid_filepaths, test_filepaths \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000016?line=2'>3</a>\u001b[0m train_set \u001b[39m=\u001b[39m csv_reader_dataset(train_filepaths, repeat\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000016?line=3'>4</a>\u001b[0m valid_set \u001b[39m=\u001b[39m csv_reader_dataset(valid_filepaths)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000016?line=4'>5</a>\u001b[0m test_set \u001b[39m=\u001b[39m csv_reader_dataset(test_filepaths)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv_reader_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_filepaths, valid_filepaths, test_filepaths = \"\", \"\", \"\"\n",
    "\n",
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TFRecord binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "  f.write(b\"This is the first record\")\n",
    "  f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"], compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Brief Intro to Protocol Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person.proto\n"
     ]
    }
   ],
   "source": [
    "%%writefile person.proto\n",
    "syntax = \"proto3\";\n",
    "message Person {\n",
    "  string name = 1;\n",
    "  int32 id = 2;\n",
    "  repeated string email =3;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Protobuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.train import BytesList, FloatList, Int64List\n",
    "#from tensorflow.train import Feature, Features, Example\n",
    "BytesList = tf.train.BytesList\n",
    "FloatList = tf.train.FloatList\n",
    "Int64List = tf.train.Int64List\n",
    "Feature = tf.train.Feature\n",
    "Features = tf.train.Features\n",
    "Example = tf.train.Example\n",
    "\n",
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
    "        }))\n",
    "\n",
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "person_example = Example(features = Features(feature = {\n",
    "  \"name\" : Feature(bytes_list = BytesList(value=[b\"Alice\"])),\n",
    "  \"id\" : Feature(int64_list = Int64List(value=[123])),\n",
    "  \"emails\" : Feature(bytes_list = BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "  f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Parsing Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "  \"name\" : tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "  \"id\" : tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "  \"emails\" : tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
    "  parsed_example = tf.io.parse_single_example(serialized_example, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example[\"emails\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).batch(10)\n",
    "for serialized_examples in dataset:\n",
    "  parsed_examples = tf.io.parse_example(serialized_examples, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'serialized_sequence_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 34'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000033?line=0'>1</a>\u001b[0m parsed_context, parsed_feature_lists \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mparse_single_sequence_example(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000033?line=1'>2</a>\u001b[0m   serialized_sequence_example, context_feature_descriptions, sequence_feature_descriptions\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000033?line=2'>3</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000033?line=3'>4</a>\u001b[0m parsed_content \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mRaggedTensor\u001b[39m.\u001b[39mfrom_sparse(parsed_feature_lists[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'serialized_sequence_example' is not defined"
     ]
    }
   ],
   "source": [
    "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
    "  serialized_sequence_example, context_feature_descriptions, sequence_feature_descriptions\n",
    ")\n",
    "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"context\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghafr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\ghafr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\ghafr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\ghafr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "C:\\Users\\ghafr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:253: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "means = np.mean(X_train, axis=0, keepdims=True)\n",
    "stds = np.std(X_train, axis=0, keepdims=True)\n",
    "eps = keras.backend.epsilon()\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.Lambda(lambda inputs : (inputs - means) / (stds + eps))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "  def adapt(self, data_sample):\n",
    "    self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "    self.stds_ =  np.std(data_sample, axis=0, keepdims=True)\n",
    "  def call(self, inputs):\n",
    "    return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 38'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000037?line=0'>1</a>\u001b[0m std_layer \u001b[39m=\u001b[39m Standardization()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000037?line=1'>2</a>\u001b[0m std_layer\u001b[39m.\u001b[39madapt(data_sample)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_sample' is not defined"
     ]
    }
   ],
   "source": [
    "std_layer = Standardization()\n",
    "std_layer.adapt(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([])\n",
    "model.add(std_layer)\n",
    "# Create the rest of the layer\n",
    "model.compile([])\n",
    "#model.fit([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab= [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
    "cat_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 2\n",
    "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.18062854, 0.4275993 ],\n",
       "       [0.529361  , 0.46778214],\n",
       "       [0.42325604, 0.60634124],\n",
       "       [0.81377685, 0.06033444],\n",
       "       [0.9822788 , 0.6797197 ],\n",
       "       [0.04322195, 0.6149744 ],\n",
       "       [0.67132413, 0.2255696 ]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.81377685, 0.06033444],\n",
       "       [0.04322195, 0.6149744 ],\n",
       "       [0.529361  , 0.46778214],\n",
       "       [0.529361  , 0.46778214]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets, output_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[-0.02378371,  0.00563369],\n",
       "       [ 0.02822248,  0.0301195 ],\n",
       "       [ 0.02673396,  0.04174472],\n",
       "       [ 0.02673396,  0.04174472]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 49'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000048?line=4'>5</a>\u001b[0m cat_embed \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mEmbedding(input_dim\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, output_dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000048?line=5'>6</a>\u001b[0m (cat_indices)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000048?line=6'>7</a>\u001b[0m encoded_inputs \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mconcatenate([regular_inputs, cat_embed])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000048?line=7'>8</a>\u001b[0m outputs \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)(encoded_inputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000048?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39m[regular_inputs, categories], outputs\u001b[39m=\u001b[39m[outputs])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merge.py:965\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=932'>933</a>\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.layers.concatenate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=933'>934</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcatenate\u001b[39m(inputs, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=934'>935</a>\u001b[0m   \u001b[39m\"\"\"Functional interface to the `Concatenate` layer.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=935'>936</a>\u001b[0m \n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=936'>937</a>\u001b[0m \u001b[39m  >>> x = np.arange(20).reshape(2, 2, 5)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=962'>963</a>\u001b[0m \u001b[39m      A tensor, the concatenation of the inputs alongside axis `axis`.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=963'>964</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=964'>965</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m Concatenate(axis\u001b[39m=\u001b[39;49maxis, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)(inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merge.py:497\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=493'>494</a>\u001b[0m \u001b[39m@tf_utils\u001b[39m\u001b[39m.\u001b[39mshape_type_conversion\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=494'>495</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, input_shape):\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=495'>496</a>\u001b[0m   \u001b[39m# Used purely for shape validation.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=496'>497</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(input_shape[\u001b[39m0\u001b[39;49m], \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(input_shape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=497'>498</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=498'>499</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mA `Concatenate` layer should be called on a list of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=499'>500</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mat least 1 input. Received: input_shape=\u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=500'>501</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m input_shape):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "categories = keras.layers.Input(shape=[],dtype=tf.string)\n",
    "cat_indices =  keras.layers.Lambda(lambda cats: table.lookup(cats))\n",
    "(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)\n",
    "(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Transform is not installed. Try running: pip3 install -U tensorflow-transform\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow_transform as tft\n",
    "\n",
    "    def preprocess(inputs):  # inputs is a batch of input features\n",
    "        median_age = inputs[\"housing_median_age\"]\n",
    "        ocean_proximity = inputs[\"ocean_proximity\"]\n",
    "        standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))\n",
    "        ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
    "        return {\n",
    "            \"standardized_median_age\": standardized_age,\n",
    "            \"ocean_proximity_id\": ocean_proximity_id\n",
    "        }\n",
    "except ImportError:\n",
    "    print(\"TF Transform is not installed. Try running: pip3 install -U tensorflow-transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 53'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000052?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfds\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000052?line=2'>3</a>\u001b[0m dataset \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39mload(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000052?line=3'>4</a>\u001b[0m mnist_train, mnist_test \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m], dataset[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 54'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000053?line=0'>1</a>\u001b[0m mnist_train \u001b[39m=\u001b[39m mnist_train\u001b[39m.\u001b[39mshuffle(\u001b[39m10000\u001b[39m)\u001b[39m.\u001b[39mbatch(\u001b[39m32\u001b[39m)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000053?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m mnist_train:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000053?line=2'>3</a>\u001b[0m   images \u001b[39m=\u001b[39m item[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_train' is not defined"
     ]
    }
   ],
   "source": [
    "mnist_train = mnist_train.shuffle(10000).batch(32).prefetch(1)\n",
    "for item in mnist_train:\n",
    "  images = item[\"image\"]\n",
    "  labels = item[\"label\"]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 55'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000054?line=0'>1</a>\u001b[0m mnist_train \u001b[39m=\u001b[39m mnist_train\u001b[39m.\u001b[39mshuffle(\u001b[39m10000\u001b[39m)\u001b[39m.\u001b[39mbatch(\u001b[39m32\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000054?line=1'>2</a>\u001b[0m mnist_train \u001b[39m=\u001b[39m mnist_train\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m items: (items[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m], items[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000054?line=2'>3</a>\u001b[0m mnist_train \u001b[39m=\u001b[39m mnist_train\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_train' is not defined"
     ]
    }
   ],
   "source": [
    "mnist_train = mnist_train.shuffle(10000).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 56'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000055?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39mload(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m\"\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, as_supervised\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000055?line=1'>2</a>\u001b[0m mnist_train \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
    "mnist_train = dataset[\"train\"].prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ghafr\\Documents\\MLPractice\\Chap13\\Chap13.ipynb Cell 57'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000056?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000056?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ghafr/Documents/MLPractice/Chap13/Chap13.ipynb#ch0000056?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mfit(mnist_train, epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\")\n",
    "model.fit(mnist_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train, y_train = X_train_full[5000:], y_train_full[5000:]\n",
    "X_val, y_val = X_train_full[:5000], y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_val, y_val)).shuffle(len(X_val))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save each dataste into a TFRecord File\n",
    "# with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "#   f.write(b\"This is the first record\")\n",
    "#   f.write(b\"And this is the second record\")\n",
    "\n",
    "def serialize_data(image,label):\n",
    "  image_data = tf.io.serialize_tensor(image)\n",
    "  return Example(\n",
    "    features = Features(\n",
    "      feature = {\n",
    "        \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "        \"label\": Feature(int64_list=Int64List(value=[label]))\n",
    "        \n",
    "      }\n",
    "    ) \n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\000\\000&\\027\\002\\000\\000Ih\\000\\004\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\002\\000\\000\\364\\327\\261\\270\\321\\264\\235\\000\\007\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\002\\000\\000;N\\0337\\206\\203\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000:R\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\002\\000\\0010>}3\\000\\000\\000\\000\\000\\000\\010s\\017\\000\\000\\000\\000\\000\\000\\000\\000\\002\\002\\004\\005\\000\\000\\210n2\\206\\254\\254\\255 \\256\\020.\\316\\327!\\000\\000\\000\\000\\000\\000\\000\\004\\000\\000\\000\\000\\000gE\\000\\000\\000\\000U\\301\\236\\276\\200\\324\\314\\034\\000\\000\\000\\000\\000\\000\\000\\003\\000\\002$\\016%_\\025\\000\\000\\000\\000\\000\\000\\0004\\234\\314\\337\\333\\000\\000\\000\\002\\003\\002\\001\\000\\003<wz]I\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000k\\367P\\000\\000\\000\\000\\003\\000\\000\\000\\000\\200\\246^\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000 \\321\\256\\000\\000\\000\\000\\000\\000\\000\\007\\010\\000\\233\\266\\3070\\000\\022\\032,9F[s\\177\\213\\205\\326\\325\\273\\205\\215\\233|06\\216\\227\\231\\213\\240\\313\\277\\377\\311\\303\\271\\264\\250\\231\\205k`YGOP@3=DiM\\000\\005\\000\\t\\016\\000\\t\\000\\000\\001\\001\\001\\001\\005\\013\\r\\020\\023\\027\\024\\022\\tYj[\\\\h\\016\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(serialize_data(image,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "import os\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "     for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                    for path in paths]\n",
    "        for index, (image,label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = serialize_data(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = write_tfrecords(\"./data/my_fashion_mnist.train\",train_set)\n",
    "test_filepaths = write_tfrecords(\"./data/my_fashion_mnist.test\",test_set)\n",
    "valid_filepaths = write_tfrecords(\"./data/my_fashion_mnist.valid\",valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value= -1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    image = tf.reshape(image,shape=[28,28])\n",
    "    return image,example[\"label\"]\n",
    "\n",
    "\n",
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                    num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X,y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i +1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
    "\n",
    "standardization = Standardization(input_shape=[28,28])\n",
    "# Now its just standardization = keras.layers.Normalization()\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"nadam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4529 - accuracy: 0.8408 - val_loss: 0.3942 - val_accuracy: 0.8590\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3385 - accuracy: 0.8789 - val_loss: 0.4163 - val_accuracy: 0.8804\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2992 - accuracy: 0.8914 - val_loss: 0.3563 - val_accuracy: 0.8838\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2768 - accuracy: 0.9007 - val_loss: 0.3447 - val_accuracy: 0.8808\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2530 - accuracy: 0.9077 - val_loss: 0.3489 - val_accuracy: 0.8890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2665cae34f0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "logs = os.path.join(os.curdir, \"my_logs\",\n",
    "                     \"run_\"+datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10\n",
    ")\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data = valid_set, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/ghafr/.keras/datasets/aclImdb')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://ai.stanford.edu/~amaas/data/sentiment/\"\n",
    "FILENAME= \"aclImdb_v1.tar.gz\"\n",
    "filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\n",
    "path = Path(filepath).parent / \"aclImdb\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\\\n",
      "   README\n",
      "   imdb.vocab\n",
      "   imdbEr.txt\n",
      "   test\\\n",
      "      labeledBow.feat\n",
      "      urls_neg.txt\n",
      "      urls_pos.txt\n",
      "      neg\\\n",
      "         0_2.txt\n",
      "         10000_4.txt\n",
      "         10001_1.txt\n",
      "         ...\n",
      "      pos\\\n",
      "         0_10.txt\n",
      "         10000_7.txt\n",
      "         10001_9.txt\n",
      "         ...\n",
      "   train\\\n",
      "      labeledBow.feat\n",
      "      unsupBow.feat\n",
      "      urls_neg.txt\n",
      "      ...\n",
      "      neg\\\n",
      "         0_3.txt\n",
      "         10000_4.txt\n",
      "         10001_4.txt\n",
      "         ...\n",
      "      pos\\\n",
      "         0_9.txt\n",
      "         10000_8.txt\n",
      "         10001_10.txt\n",
      "         ...\n",
      "      unsup\\\n",
      "         0_0.txt\n",
      "         10000_0.txt\n",
      "         10001_0.txt\n",
      "         ...\n"
     ]
    }
   ],
   "source": [
    "for name, subdirs, files in os.walk(path):\n",
    "  indent = len(Path(name).parts) - len(path.parts)\n",
    "  print(\"   \" * indent + Path(name).parts[-1] + os.sep)\n",
    "  for index, filename in enumerate(sorted(files)):\n",
    "    if index == 3:\n",
    "      print(\"   \" * (indent + 1) + \"...\")\n",
    "      break\n",
    "    print(\"   \" * (indent + 1) + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_paths(dirpath):\n",
    "  return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(test_valid_pos)\n",
    "\n",
    "test_pos = test_valid_pos[:5000]\n",
    "test_neg = test_valid_neg[:5000]\n",
    "valid_pos = test_valid_pos[5000:]\n",
    "valid_neg = test_valid_neg[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath) as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.constant(reviews), tf.constant(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 194: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2588/1372886619.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimdb_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_neg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2588/2294397609.py\u001b[0m in \u001b[0;36mimdb_dataset\u001b[1;34m(filepaths_positive, filepaths_negative)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreview_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 \u001b[0mreviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     return tf.data.Dataset.from_tensor_slices(\n",
      "\u001b[1;32mC:\\Program Files\\Python39\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 194: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "for X, y in imdb_dataset(train_pos, train_neg).take(3):\n",
    "  print(X)\n",
    "  print(y)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
